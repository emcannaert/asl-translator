{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32814c4-30cc-451c-ba8d-1ff4f09cb997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as transform\n",
    "from torch.nn.functional import normalize\n",
    "from PIL import Image\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import albumentations\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb0ca6-723d-49a8-8d3c-592a0d3d42b0",
   "metadata": {},
   "source": [
    "### 1. Get training dataset in usable format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1a25c2-595e-4037-b053-62879bc9096b",
   "metadata": {},
   "source": [
    "- images are in jpg format, need to convert these to PyTorch tensors\n",
    "- tensors also have to be normalized  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f8cd005-68e1-4e32-bd1b-c47b3bccb3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torchvision.io.read_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2261e9bc-79e9-4a1a-8312-51a60ec45ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### class to load and store relevant data \n",
    "class LoadImageData:   \n",
    "    def __init__(self, n_files_per_class=10000):  ### n_files == number of files of each letter to train on\n",
    "        self.label_converter = dict()\n",
    "        self.convert_label_to_int()\n",
    "        self.n_files_per_class = n_files_per_class\n",
    "        self.train_data    = [] # train data paths, no longer in tensor format\n",
    "        self.test_data     = [] # test data paths, no longer in tensor format\n",
    "        self.train_labels = [] # truth LETTER label for training data\n",
    "        self.test_labels   = [] # truth LETTER label for test data\n",
    "        self.train_labels_num =  [] # truth NUMBER label for training data\n",
    "        self.test_labels_num  =  [] # truth NUMBER label for test data\n",
    "        \n",
    "        self.image_path_dict = dict() # dictionary of all training file paths\n",
    "        self.load_train_data()\n",
    "        self.load_test_data()\n",
    "        \n",
    "        self.transf = albumentations.Compose([\n",
    "            albumentations.Resize(224, 224, always_apply=True),\n",
    "        ])\n",
    "    ### helper function to convert str letters/del/space into numbers \n",
    "    def convert_label_to_int(self):\n",
    "        alphabet = \"A/B/C/D/E/F/G/H/I/J/K/L/M/N/O/P/Q/R/S/T/U/V/W/X/Y/Z/del/nothing/space\"\n",
    "        for iii,label in enumerate(alphabet.split(\"/\")):\n",
    "            self.label_converter[label] = iii\n",
    "    \n",
    "    ### load training data into the instance variable train_data\n",
    "    def load_train_data(self):\n",
    "        now = time.time()\n",
    "        train_path = \"datasets/asl_alphabet_train/asl_alphabet_train/\"\n",
    "        train_directories = glob.glob(train_path+\"/*\")\n",
    "        n_files = 0\n",
    "        print(\" ----- Loading training dataset -----\")\n",
    "\n",
    "        for dir in train_directories:\n",
    "            letter = dir.split(\"/\")[-1]\n",
    "            self.image_path_dict[letter] = []\n",
    "            n_test_for_class = 0 \n",
    "            for image_file in glob.glob(dir+\"/*\"):\n",
    "                if n_test_for_class > (self.n_files_per_class-1):\n",
    "                    break ### move onto the next letter \n",
    "                self.image_path_dict[letter].append(image_file)\n",
    "                self.train_data.append( image_file )\n",
    "                self.train_labels_num.append(self.label_converter[letter])\n",
    "                self.train_labels.append(letter)\n",
    "                n_test_for_class+=1\n",
    "                n_files +=1\n",
    "            print(\"Finished importing %s\"%letter)\n",
    "        print(\"Done with training dataset - loaded paths for %i files. Took %f seconds\"%(n_files, np.around(time.time()-now)))\n",
    "        return\n",
    "    ### load test data into the instance variable train_data\n",
    "    def load_test_data(self):\n",
    "        now = time.time()\n",
    "        test_path = \"datasets/asl_alphabet_test/asl_alphabet_test/\"\n",
    "        test_directories = glob.glob(test_path+\"/*\")\n",
    "        n_files = 0\n",
    "        print(\"----- Loading test dataset -----\")\n",
    "        for image_file in test_directories:\n",
    "            letter = image_file.split(\"_\")[-2].split(\"/\")[-1]\n",
    "            self.image_path_dict[letter] = []\n",
    "            self.image_path_dict[letter].append(image_file)\n",
    "            self.test_data.append(image_file   )\n",
    "            self.test_labels_num.append(self.label_converter[letter])\n",
    "            self.test_labels.append(letter)\n",
    "            n_files +=1\n",
    "        print(\"Done with test dataset - loaded paths for %i files. Took %f seconds\"%(n_files, np.around(time.time()-now,4)))\n",
    "        return\n",
    "    def __getitem__(self,i):\n",
    "        image = cv2.imread(self.train_data[i])\n",
    "        image = self.transf(image=np.array(image))['image']\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        label = self.train_labels[i]\n",
    "        return torch.tensor(image, dtype=torch.float), torch.tensor(label, dtype=torch.long)\n",
    "### lighter class to store test/train paths and labels\n",
    "class ImageData:\n",
    "    def __init__(self,paths, labels):\n",
    "        self.X = paths\n",
    "        self.y = labels\n",
    "        self.transf = albumentations.Compose([\n",
    "            albumentations.Resize(224, 224, always_apply=True),\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return (len(self.X))\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        image = cv2.imread(self.X[i])\n",
    "        image = self.transf(image=np.array(image))['image']\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        label = self.y[i]\n",
    "        return torch.tensor(image, dtype=torch.float), torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b581c-adcc-49f6-a82f-eb8415b77ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c80220e5-acf4-4c78-9ff5-d6845bcb03fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----- Loading training dataset -----\n",
      "Finished importing R\n",
      "Finished importing U\n",
      "Finished importing I\n",
      "Finished importing N\n",
      "Finished importing G\n",
      "Finished importing Z\n",
      "Finished importing T\n",
      "Finished importing S\n",
      "Finished importing A\n",
      "Finished importing F\n",
      "Finished importing O\n",
      "Finished importing H\n",
      "Finished importing del\n",
      "Finished importing nothing\n",
      "Finished importing space\n",
      "Finished importing M\n",
      "Finished importing J\n",
      "Finished importing C\n",
      "Finished importing D\n",
      "Finished importing V\n",
      "Finished importing Q\n",
      "Finished importing X\n",
      "Finished importing E\n",
      "Finished importing B\n",
      "Finished importing K\n",
      "Finished importing L\n",
      "Finished importing Y\n",
      "Finished importing P\n",
      "Finished importing W\n",
      "Done with training dataset - loaded paths for 29000 files. Took 0.000000 seconds\n",
      "----- Loading test dataset -----\n",
      "Done with test dataset - loaded paths for 28 files. Took 0.000400 seconds\n"
     ]
    }
   ],
   "source": [
    "datasets = LoadImageData(1000) ## data instance, passing in 1000 so that only 1000 of each letter are used for training \n",
    "### changing gears, keeping the \"data\" as the file paths to each jpg, also imbuing this class with a __get__\n",
    "### built-in method that returns the relevent tensors for when these are needed \n",
    "\n",
    "train_data = ImageData(datasets.train_data, datasets.train_labels_num)\n",
    "test_data  = ImageData(datasets.test_data, datasets.test_labels_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222cf2ba-d5ea-4b3a-8f78-0eb3d25a3759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48abec70-c546-4235-bf06-016c83cc9c2b",
   "metadata": {},
   "source": [
    "### 2. Create a csv with the file path, corresponding, letter, and then binarize this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccc45c35-1672-4af6-a6d1-f7bd9fd26e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.DataFrame()\n",
    "df_training['path'] = \"\"\n",
    "df_training['letter'] = \"\"\n",
    "for iii in range(0,len(datasets.train_data)):\n",
    "    df_training.loc[iii, 'path' ] = datasets.train_data[iii]\n",
    "    df_training.loc[iii, 'letter' ] = datasets.train_labels[iii] ### converting letter to int\n",
    "df_training = df_training.sample(frac=1).reset_index(drop=True) ### shuffle\n",
    "df_training.to_csv(\"processedDatasets/train_data.csv\") ### write out csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0f1071f-843b-4670-8912-60a4d392a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_binarized = pd.get_dummies(df_training[\"letter\"],dtype=int) ### binarize\n",
    "letters_binarized.insert(0, 'path', df_training['path']) ### reinsert the path \n",
    "letters_binarized.to_csv(\"processedDatasets/train_data_binarized.csv\") ### write out binarized csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f75ba6a-0908-4853-8bd1-5875ee6f22d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>...</th>\n",
       "      <th>T</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>del</th>\n",
       "      <th>nothing</th>\n",
       "      <th>space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  A  B  C  D  E  F  G  H  \\\n",
       "0  datasets/asl_alphabet_train/asl_alphabet_train...  0  0  0  0  0  0  0  0   \n",
       "1  datasets/asl_alphabet_train/asl_alphabet_train...  0  0  0  0  0  0  0  0   \n",
       "2  datasets/asl_alphabet_train/asl_alphabet_train...  0  0  0  0  0  0  0  0   \n",
       "3  datasets/asl_alphabet_train/asl_alphabet_train...  0  0  0  0  0  0  0  0   \n",
       "4  datasets/asl_alphabet_train/asl_alphabet_train...  0  0  1  0  0  0  0  0   \n",
       "5  datasets/asl_alphabet_train/asl_alphabet_train...  0  0  1  0  0  0  0  0   \n",
       "6  datasets/asl_alphabet_train/asl_alphabet_train...  0  0  0  0  0  0  0  0   \n",
       "7  datasets/asl_alphabet_train/asl_alphabet_train...  0  0  0  0  0  1  0  0   \n",
       "8  datasets/asl_alphabet_train/asl_alphabet_train...  0  0  0  0  0  0  0  0   \n",
       "9  datasets/asl_alphabet_train/asl_alphabet_train...  0  0  0  0  0  0  0  0   \n",
       "\n",
       "   I  ...  T  U  V  W  X  Y  Z  del  nothing  space  \n",
       "0  0  ...  0  0  0  0  0  0  0    0        0      0  \n",
       "1  0  ...  0  0  0  0  0  0  0    0        0      1  \n",
       "2  0  ...  0  0  0  0  0  0  0    1        0      0  \n",
       "3  0  ...  0  0  0  0  0  0  0    0        0      0  \n",
       "4  0  ...  0  0  0  0  0  0  0    0        0      0  \n",
       "5  0  ...  0  0  0  0  0  0  0    0        0      0  \n",
       "6  0  ...  0  0  0  0  0  0  0    0        0      0  \n",
       "7  0  ...  0  0  0  0  0  0  0    0        0      0  \n",
       "8  0  ...  0  0  0  0  0  0  0    0        0      0  \n",
       "9  0  ...  0  0  0  0  0  0  0    0        0      0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters_binarized.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731f4e7e",
   "metadata": {},
   "source": [
    "### 2.5 Save labels in a loadable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dda4c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sklearn.preprocessing\n",
    "\n",
    "\n",
    "    \n",
    "binarized_labels = sklearn.preprocessing.label_binarize(datasets.train_labels, classes = np.array(\"A/B/C/D/E/F/G/H/I/J/K/L/M/N/O/P/Q/R/S/T/U/V/W/X/Y/Z/del/nothing/space\".split(\"/\")))\n",
    "with open('processedDatasets/labels_binarized.pickle', 'wb') as handle:\n",
    "    pickle.dump(binarized_labels, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### test pickle file is working\n",
    "binarized_labels_pkl = open('processedDatasets/labels_binarized.pickle', 'rb')\n",
    "# dump information to that file\n",
    "binarized_labels_loaded = pickle.load(binarized_labels_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300d1f29",
   "metadata": {},
   "source": [
    "### 3. Define NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0251d49d-c31e-4cb1-87e0-767348004c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "### custon CNN, inherits from base torch.nn \n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN,self).__init__()  ## override __init__ to be from nn.Module base class\n",
    "        self.conv1 = nn.Conv2d(3,16,5) # 3 channels in, 16 channels out, kernel size 5\n",
    "        self.conv2 = nn.Conv2d(16,32,5)\n",
    "        self.conv3 = nn.Conv2d(32,64,3)\n",
    "        self.conv4 = nn.Conv2d(64,128,5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128,256)\n",
    "        self.fc2 = nn.Linear(256, len(binarized_labels[0]))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    def forward(self,x): # passed in input tensor\n",
    "        x = self.pool(F.relu(self.conv1(x))) # convolutional layer followed by relu mapping and then a pool layer\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        ### get the tensor shape\n",
    "        t_layers, t_width, t_height = x.shape\n",
    "        x = F.adaptive_avg_pool2d(x,1).reshape(t_layers,-1)    ### reshape this to be 1D, dimensions are inferred \n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x) ### return tensor of length 29 \n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4a720e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_nn = CustomCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b348b5-cecb-4ccb-a53c-fa7ae9031743",
   "metadata": {},
   "source": [
    "### 4. Set Up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f3cc32f-bc7d-42e4-8e3b-62b4af051189",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set seeds for random, np, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29993d6d-985d-41d2-9503-d6497a16b373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not found - using CPU.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import CustomNN class\n",
    "\n",
    "def set_seeds(seed_):\n",
    "    np.random.seed(seed_)\n",
    "    random.seed(seed_)\n",
    "    torch.cuda.manual_seed(seed_)\n",
    "    torch.cuda.manual_seed_all(seed_)\n",
    "    torch.manual_seed(seed_)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    return\n",
    "SEED = 96\n",
    "set_seeds(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = ('cuda:0')\n",
    "    print(\"Found CUDA:0 - using CUDA.\")\n",
    "else:\n",
    "    device = ('cpu')\n",
    "    print(\"CUDA not found - using CPU.\")\n",
    "### API for interfacing with GPU, (Compute Unified Device Architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c5ddac7-09ac-4434-9079-17250d8270d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished splitting dataset into train and validation.\n"
     ]
    }
   ],
   "source": [
    "### get images from LoadImageData class\n",
    "\n",
    "\n",
    "X = datasets.train_data\n",
    "y = datasets.train_labels\n",
    "\n",
    "### shuffle train and test with same indices\n",
    "zipped_Xy = list(zip(X, y))\n",
    "random.shuffle(zipped_Xy)\n",
    "X, y = zip(*zipped_Xy)\n",
    "\n",
    "(xtrain, xtest, ytrain, ytest) = (train_test_split(X, y, \n",
    "                                test_size=0.15, random_state=SEED))\n",
    "print(\"Finished splitting dataset into train and validation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2a8288c-33e5-4f61-8bb1-b0f47476fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### init data loaders\n",
    "train_dataset    = ImageData(xtrain,ytrain)\n",
    "validate_dataset = ImageData(xtest,ytest)\n",
    "\n",
    "batch_size = 4 \n",
    "### now load data into ptytorch\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95c471fe-9072-4c01-84ed-df51cb38a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomCNN().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5418c48-47d6-4b21-8f09-1bd7ed9fda78",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03ba168a-e4c4-4a88-bc95-725231860bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(model.parameters(), lr=0.001) # construct an optimizer object that will hold the current state and will update the parameters based on the computed gradients., learning rate = 0.001\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ef54b-28fc-4511-b95e-113ae504f783",
   "metadata": {},
   "source": [
    "### 5. Do Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9050498-231b-4c3c-b975-a627efe9b3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/ethan/miniconda3/envs/ml/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/ethan/miniconda3/envs/ml/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'ImageData' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Running %s\"%i)\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 0:    # give update every 1000 minibatches\n",
    "            print(\"epoch %s, loss: %f\"%(i,running_loss/1000.))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2f6ff-1eb9-47ac-a660-6a7f4dcc4839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
