{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32814c4-30cc-451c-ba8d-1ff4f09cb997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb0ca6-723d-49a8-8d3c-592a0d3d42b0",
   "metadata": {},
   "source": [
    "### 1. Get training dataset in usable format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1a25c2-595e-4037-b053-62879bc9096b",
   "metadata": {},
   "source": [
    "- images are in jpg format, need to convert these to PIL Images that will then be converted into tensors\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8cd005-68e1-4e32-bd1b-c47b3bccb3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2261e9bc-79e9-4a1a-8312-51a60ec45ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### class to load and store data\n",
    "class image_data:   \n",
    "    def __init__(self):\n",
    "        self.label_converter = dict()\n",
    "        self.convert_label_to_int()\n",
    "        self.train_data    = [] # train data in tensor format\n",
    "        self.test_data     = [] # test data in tensor format\n",
    "        self.validate_data = [] # validation data in tensor format\n",
    "        self.train_labels =  []\n",
    "        self.test_labels  =  []\n",
    "        self.image_files = dict()\n",
    "        self.load_train_data()\n",
    "        self.load_test_data()\n",
    "\n",
    "    ### helper function to convert str letters/del/space into numbers \n",
    "    def convert_label_to_int(self):\n",
    "        alphabet = \"A/B/C/D/E/F/G/H/I/J/K/L/M/N/O/P/Q/R/S/T/U/V/W/X/Y/Z/del/nothing/space\"\n",
    "        for iii,label in enumerate(alphabet.split(\"/\")):\n",
    "            self.label_converter[label] = iii\n",
    "    ### give this an image filename and it will return the transformed tensor \n",
    "    def convert_jpg_to_tensor(self,filepath):\n",
    "        image = Image.open(filepath) \n",
    "          \n",
    "        # Define a transform to convert PIL  \n",
    "        # image to a Torch tensor \n",
    "        transform = transforms.Compose([ \n",
    "            transforms.PILToTensor() \n",
    "        ]) \n",
    "          \n",
    "        # transform = transforms.PILToTensor() \n",
    "        # Convert the PIL image to Torch tensor \n",
    "        return transform(image)\n",
    "    ### load training data into the instance variable train_data\n",
    "    def load_train_data(self):\n",
    "        now = time.time()\n",
    "        train_path = \"datasets/asl_alphabet_train/asl_alphabet_train/\"\n",
    "        train_directories = glob.glob(train_path+\"/*\")\n",
    "        n_files = 0\n",
    "        print(\" ----- Loading training dataset -----\")\n",
    "        for dir in train_directories:\n",
    "            letter = dir.split(\"/\")[-1]\n",
    "            self.image_files[letter] = []\n",
    "            \n",
    "            for image_file in glob.glob(dir+\"/*\"):\n",
    "                #print(image_file)\n",
    "                self.image_files[letter].append(image_file)\n",
    "                self.train_data.append(self.convert_jpg_to_tensor(image_file))\n",
    "                self.train_labels.append(self.label_converter[letter])\n",
    "                n_files +=1\n",
    "            print(\"Finished importing %s\"%letter)\n",
    "        #print(\"Found training file directories - \", train_filepaths)\n",
    "        print(\"Done with training dataset - converted %i files. Took %f seconds\"%(n_files, time.time()-now))\n",
    "        return\n",
    "    ### load test data into the instance variable train_data\n",
    "    def load_test_data(self):\n",
    "        now = time.time()\n",
    "        test_path = \"datasets/asl_alphabet_test/asl_alphabet_test/\"\n",
    "        test_directories = glob.glob(test_path+\"/*\")\n",
    "        n_files = 0\n",
    "        print(\"----- Loading test dataset -----\")\n",
    "        \n",
    "        for image_file in test_directories:\n",
    "            letter = image_file.split(\"_\")[-2].split(\"/\")[-1]\n",
    "            self.image_files[letter] = []\n",
    "            self.image_files[letter].append(image_file)\n",
    "            self.test_data.append(self.convert_jpg_to_tensor(image_file))\n",
    "            self.test_labels.append(self.label_converter[letter])\n",
    "            n_files +=1\n",
    "        print(\"Done with test dataset - converted %i files. Took %f seconds\"%(n_files, time.time()-now))\n",
    "        return\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c80220e5-acf4-4c78-9ff5-d6845bcb03fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----- Loading training dataset -----\n",
      "Finished importing R\n",
      "Finished importing U\n",
      "Finished importing I\n",
      "Finished importing N\n",
      "Finished importing G\n",
      "Finished importing Z\n",
      "Finished importing T\n",
      "Finished importing S\n",
      "Finished importing A\n",
      "Finished importing F\n",
      "Finished importing O\n",
      "Finished importing H\n",
      "Finished importing del\n",
      "Finished importing nothing\n",
      "Finished importing space\n",
      "Finished importing M\n",
      "Finished importing J\n",
      "Finished importing C\n",
      "Finished importing D\n",
      "Finished importing V\n",
      "Finished importing Q\n",
      "Finished importing X\n",
      "Finished importing E\n",
      "Finished importing B\n",
      "Finished importing K\n",
      "Finished importing L\n",
      "Finished importing Y\n",
      "Finished importing P\n",
      "Finished importing W\n",
      "Done with training dataset - converted 87000 files. Took 58.728651 seconds\n",
      "----- Loading test dataset -----\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/F_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/G_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/L_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/M_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/R_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/S_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/X_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/Y_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/U_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/T_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/A_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/K_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/J_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/Z_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/nothing_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/Q_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/P_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/space_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/O_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/N_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/E_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/D_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/H_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/I_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/B_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/C_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/V_test.jpg\n",
      "datasets/asl_alphabet_test/asl_alphabet_test/W_test.jpg\n",
      "Done with test dataset - converted 28 files. Took 0.014453 seconds\n"
     ]
    }
   ],
   "source": [
    "id = image_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222cf2ba-d5ea-4b3a-8f78-0eb3d25a3759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
