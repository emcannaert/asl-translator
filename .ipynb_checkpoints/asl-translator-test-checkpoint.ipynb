{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a32814c4-30cc-451c-ba8d-1ff4f09cb997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as transform\n",
    "from torch.nn.functional import normalize\n",
    "from PIL import Image\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import albumentations\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb0ca6-723d-49a8-8d3c-592a0d3d42b0",
   "metadata": {},
   "source": [
    "### 1. Get training dataset in usable format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1a25c2-595e-4037-b053-62879bc9096b",
   "metadata": {},
   "source": [
    "- images are in jpg format, need to convert these to PyTorch tensors\n",
    "- tensors also have to be normalized  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f8cd005-68e1-4e32-bd1b-c47b3bccb3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torchvision.io.read_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2261e9bc-79e9-4a1a-8312-51a60ec45ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### class to load and store data\n",
    "class image_data:   \n",
    "    def __init__(self, n_files_per_class=10000):  ### n_files == number of files of each letter to train on\n",
    "        self.label_converter = dict()\n",
    "        self.convert_label_to_int()\n",
    "        self.n_files_per_class = n_files_per_class\n",
    "        self.train_data    = [] # train data paths, no longer in tensor format\n",
    "        self.test_data     = [] # test data paths, no longer in tensor format\n",
    "        \n",
    "        self.train_labels =  [] # truth label for training data\n",
    "        self.test_labels  =  [] # truth label for test data\n",
    "        self.image_path_dict = dict() # dictionary of all training file paths\n",
    "        self.load_train_data()\n",
    "        self.load_test_data()\n",
    "        \n",
    "        self.transf = albumentations.Compose([\n",
    "            albumentations.Resize(224, 224, always_apply=True),\n",
    "        ])\n",
    "    ### helper function to convert str letters/del/space into numbers \n",
    "    def convert_label_to_int(self):\n",
    "        alphabet = \"A/B/C/D/E/F/G/H/I/J/K/L/M/N/O/P/Q/R/S/T/U/V/W/X/Y/Z/del/nothing/space\"\n",
    "        for iii,label in enumerate(alphabet.split(\"/\")):\n",
    "            self.label_converter[label] = iii\n",
    "    \n",
    "    ### load training data into the instance variable train_data\n",
    "    def load_train_data(self):\n",
    "        now = time.time()\n",
    "        train_path = \"datasets/asl_alphabet_train/asl_alphabet_train/\"\n",
    "        train_directories = glob.glob(train_path+\"/*\")\n",
    "        n_files = 0\n",
    "        print(\" ----- Loading training dataset -----\")\n",
    "\n",
    "        for dir in train_directories:\n",
    "            letter = dir.split(\"/\")[-1]\n",
    "            self.image_path_dict[letter] = []\n",
    "            n_test_for_class = 0 \n",
    "            for image_file in glob.glob(dir+\"/*\"):\n",
    "                if n_test_for_class > (self.n_files_per_class-1):\n",
    "                    break ### move onto the next letter \n",
    "                self.image_path_dict[letter].append(image_file)\n",
    "                self.train_data.append( image_file )\n",
    "                self.train_labels.append(self.label_converter[letter])\n",
    "                n_test_for_class+=1\n",
    "                n_files +=1\n",
    "            print(\"Finished importing %s\"%letter)\n",
    "        print(\"Done with training dataset - loaded paths for %i files. Took %f seconds\"%(n_files, np.around(time.time()-now)))\n",
    "        return\n",
    "    ### load test data into the instance variable train_data\n",
    "    def load_test_data(self):\n",
    "        now = time.time()\n",
    "        test_path = \"datasets/asl_alphabet_test/asl_alphabet_test/\"\n",
    "        test_directories = glob.glob(test_path+\"/*\")\n",
    "        n_files = 0\n",
    "        print(\"----- Loading test dataset -----\")\n",
    "        for image_file in test_directories:\n",
    "            letter = image_file.split(\"_\")[-2].split(\"/\")[-1]\n",
    "            self.image_path_dict[letter] = []\n",
    "            self.image_path_dict[letter].append(image_file)\n",
    "            self.test_data.append(image_file   )\n",
    "            self.test_labels.append(self.label_converter[letter])\n",
    "            n_files +=1\n",
    "        print(\"Done with test dataset - loaded paths for %i files. Took %f seconds\"%(n_files, np.around(time.time()-now,4)))\n",
    "        return\n",
    "    def __getitem__(self,i):\n",
    "        image = cv2.imread(self.train_data[i])\n",
    "        image = self.transf(image=np.array(image))['image']\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        label = self.train_labels[i]\n",
    "        \n",
    "        return torch.tensor(image, dtype=torch.float), torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b581c-adcc-49f6-a82f-eb8415b77ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c80220e5-acf4-4c78-9ff5-d6845bcb03fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----- Loading training dataset -----\n",
      "Finished importing R\n",
      "Finished importing U\n",
      "Finished importing I\n",
      "Finished importing N\n",
      "Finished importing G\n",
      "Finished importing Z\n",
      "Finished importing T\n",
      "Finished importing S\n",
      "Finished importing A\n",
      "Finished importing F\n",
      "Finished importing O\n",
      "Finished importing H\n",
      "Finished importing del\n",
      "Finished importing nothing\n",
      "Finished importing space\n",
      "Finished importing M\n",
      "Finished importing J\n",
      "Finished importing C\n",
      "Finished importing D\n",
      "Finished importing V\n",
      "Finished importing Q\n",
      "Finished importing X\n",
      "Finished importing E\n",
      "Finished importing B\n",
      "Finished importing K\n",
      "Finished importing L\n",
      "Finished importing Y\n",
      "Finished importing P\n",
      "Finished importing W\n",
      "Done with training dataset - loaded paths for 29000 files. Took 0.000000 seconds\n",
      "----- Loading test dataset -----\n",
      "Done with test dataset - loaded paths for 28 files. Took 0.000200 seconds\n"
     ]
    }
   ],
   "source": [
    "id_ = image_data(1000) ## data instance, passing in 1000 so that only 1000 of each letter are used for training \n",
    "### changing gears, keeping the \"data\" as the file paths to each jpg, also imbuing this class with a __get__\n",
    "### built-in method that returns the relevent tensors for when these are needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "222cf2ba-d5ea-4b3a-8f78-0eb3d25a3759",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4 \n",
    "### now load data into ptytorch\n",
    "trainloader = torch.utils.data.DataLoader(id_.train_data, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(id_.test_data, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48abec70-c546-4235-bf06-016c83cc9c2b",
   "metadata": {},
   "source": [
    "### Create a csv with the file path, corresponding, letter, and then binarize this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ccc45c35-1672-4af6-a6d1-f7bd9fd26e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.DataFrame()\n",
    "df_training['path'] = \"\"\n",
    "df_training['letter'] = \"\"\n",
    "for iii in range(0,len(id_.train_data)):\n",
    "    df_training.loc[iii, 'path' ] = id_.train_data[iii]\n",
    "    df_training.loc[iii, 'letter' ] = id_.train_labels[iii]\n",
    "df_training = df_training.sample(frac=1).reset_index(drop=True) ### shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0f1071f-843b-4670-8912-60a4d392a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_binarized = pd.get_dummies(df_training[\"letter\"],dtype=int) ### binarize\n",
    "df[\"somecolumn\"] = df[\"somecolumn\"].astype(int)\n",
    "letters_binarized.insert(0, 'path', df_training['path']) ### reinsert the path \n",
    "letters_binarized.to_csv(\"/Users/ethan/Documents/Projects/ml/asl-translator/processedDatasets/train_data_binarized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f75ba6a-0908-4853-8bd1-5875ee6f22d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>datasets/asl_alphabet_train/asl_alphabet_train...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path      0      1      2  \\\n",
       "0  datasets/asl_alphabet_train/asl_alphabet_train...  False  False   True   \n",
       "1  datasets/asl_alphabet_train/asl_alphabet_train...  False  False  False   \n",
       "2  datasets/asl_alphabet_train/asl_alphabet_train...  False  False  False   \n",
       "3  datasets/asl_alphabet_train/asl_alphabet_train...  False  False  False   \n",
       "4  datasets/asl_alphabet_train/asl_alphabet_train...  False  False  False   \n",
       "5  datasets/asl_alphabet_train/asl_alphabet_train...  False  False  False   \n",
       "6  datasets/asl_alphabet_train/asl_alphabet_train...  False  False  False   \n",
       "7  datasets/asl_alphabet_train/asl_alphabet_train...  False  False  False   \n",
       "8  datasets/asl_alphabet_train/asl_alphabet_train...  False  False  False   \n",
       "9  datasets/asl_alphabet_train/asl_alphabet_train...  False  False  False   \n",
       "\n",
       "       3      4      5      6      7      8  ...     19     20     21     22  \\\n",
       "0  False  False  False  False  False  False  ...  False  False  False  False   \n",
       "1  False  False  False  False  False  False  ...  False  False  False  False   \n",
       "2  False  False  False  False  False  False  ...  False  False  False  False   \n",
       "3  False  False  False  False  False  False  ...  False  False  False  False   \n",
       "4  False  False  False   True  False  False  ...  False  False  False  False   \n",
       "5  False  False  False  False  False  False  ...  False   True  False  False   \n",
       "6  False  False  False  False  False  False  ...   True  False  False  False   \n",
       "7   True  False  False  False  False  False  ...  False  False  False  False   \n",
       "8  False  False  False   True  False  False  ...  False  False  False  False   \n",
       "9  False  False  False  False  False  False  ...  False  False  False  False   \n",
       "\n",
       "      23     24     25     26     27     28  \n",
       "0  False  False  False  False  False  False  \n",
       "1  False  False  False   True  False  False  \n",
       "2  False  False  False  False  False  False  \n",
       "3   True  False  False  False  False  False  \n",
       "4  False  False  False  False  False  False  \n",
       "5  False  False  False  False  False  False  \n",
       "6  False  False  False  False  False  False  \n",
       "7  False  False  False  False  False  False  \n",
       "8  False  False  False  False  False  False  \n",
       "9  False  False  False  False  False  False  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters_binarized.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c5c32-181d-455c-af06-003d91dd753d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0251d49d-c31e-4cb1-87e0-767348004c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
